{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fjHd  ->  ව්‍යො  #  ව්‍යො  #  True\n",
      "fIda  ->  ෂෝ  #  ෂෝ  #  True\n",
      "fId  ->  ෂො  #  ෂො  #  True\n",
      "fâ  ->  ඩේ  #  ඬේ  #  False\n",
      "Ï  ->  ඐ  #  ඐ  #  True\n",
      "\\/  ->  රැ  #  රැ=  #  False\n",
      "Ú  ->  ඵී  #  ඵී  #  True\n",
      "È  ->  දි  #  දි  #  True\n",
      "Ý  ->  ඵි  #  ඵී  #  False\n",
      "Ü  ->  ට්  #  ට්  #  True\n",
      "Ù  ->  ඩ්  #  ඕ  #  False\n",
      "Ì  ->  ඏ  #  ඏ  #  True\n",
      "M  ->  ඵ  #  ඵ  #  True\n",
      "c  ->  ජ  #  ජ  #  True\n",
      "r  ->  ර  #  ර  #  True\n",
      "{  ->  ඥ  #  ඥ  #  True\n",
      "|  ->  ඳ  #  ඳ  #  True\n",
      "~  ->  ඬ  #  ඬ  #  True\n",
      "&  ->  )  #  )  #  True\n",
      "Z  ->  ’  #  ’  #  True\n",
      "•  ->  x  #  x  #  True\n",
      "º  ->  X  #  X  #  True\n",
      "¹  ->  V  #  V  #  True\n",
      "Total mappings:  546\n",
      "Unique mappings:  523\n"
     ]
    }
   ],
   "source": [
    "key_set = set()\n",
    "mappings = {}\n",
    "with open(\"ucsc_mapping.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    line_count = 0\n",
    "    for line in f.readlines():\n",
    "        line_count += 1\n",
    "        fm, uni = line.strip().split(\": \")\n",
    "        fm = fm[1:-1]\n",
    "        uni = uni[1:-1]\n",
    "        if fm in key_set:\n",
    "            print(fm, \" -> \", uni, \" # \", mappings[fm], \" # \", mappings[fm] == uni)\n",
    "        else:\n",
    "            key_set.add(fm)\n",
    "            mappings[fm] = uni\n",
    "\n",
    "print(\"Total mappings: \", line_count)\n",
    "print(\"Unique mappings: \", len(mappings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for 4, rest of the duplicates are same mapping.\n",
    "\n",
    "\"fâ\"  ->  \"ඩේ\"  #  \"ඬේ\"  #  False ==>> Key for \"ඬේ\" should be 'få'. Added it.\n",
    "\n",
    "\"\\/\"  ->  \"රැ\"  #  \"රැ=\"  #  False ==>> \"රැ=\" seems wrong\n",
    "\n",
    "\"Ý\"  ->  \"ඵි\"  #  \"ඵී\"  #  False ==>> Key for 'ඵී' is 'Ú'\n",
    "\n",
    "\"Ù\"  ->  \"ඩ්\"  #  \"ඕ\"  #  False ==>> Neither is correct. \"Ù\": \"ඞ්\" and \"â\": \"ඩ්\"\n",
    "\n",
    "Remove rest of the dupes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total deduped mappings:  524\n",
      "Unique deduped mappings:  524\n",
      "Additional key:  ['få']\n"
     ]
    }
   ],
   "source": [
    "key_set_1 = set()\n",
    "mappings_1 = {}\n",
    "with open(\"ucsc_deduped.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    line_count = 0\n",
    "    for line in f.readlines():\n",
    "        line_count += 1\n",
    "        fm, uni = line.strip().split(\": \")\n",
    "        fm = fm[1:-1]\n",
    "        uni = uni[1:-1]\n",
    "        if fm in key_set_1:\n",
    "            print(fm, \" -> \", uni, \" # \", mappings_1[fm], \" # \", mappings_1[fm] == uni)\n",
    "        else:\n",
    "            key_set_1.add(fm)\n",
    "            mappings_1[fm] = uni\n",
    "\n",
    "print(\"Total deduped mappings: \", line_count)\n",
    "print(\"Unique deduped mappings: \", len(mappings_1))\n",
    "print(\"Additional key: \", list(key_set_1 - key_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ƒ': 'ඳැ='\n",
      "'ü': 'ඤූ='\n",
      "'û': 'ඤු='\n",
      "'´': ' ඕ'\n",
      "'P': 'ඡ='\n",
      "'“': ' ර්‍ණ'\n",
      "' ’': 'ී'\n",
      "' ‘': 'ි'\n",
      "'œ': ' ර්‍්‍ය'\n"
     ]
    }
   ],
   "source": [
    "for key, uni in mappings_1.items():\n",
    "    if re.search(r\" \\w+\", uni) or re.search(r\" .+\", key) or re.search(r\".+=\", uni):\n",
    "        print(f\"'{key}': '{uni}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure about ' ’': 'ී' and ' ‘': 'ි'. Leaving them as is for now. \n",
    "\n",
    "Fixing the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\"%a\": \"a%\"\n",
    "\"f*%a\": \"ෆ්‍රේ\"\n",
    "\"f.%a\": \"ග්‍රේ\"\n",
    "\"fl%a\": \"ක්‍රේ\"\n",
    "\"fm%a\": \"ප්‍රේ\"\n",
    "```\n",
    "There is a problem with `a%`. Since it can be used as either `a%` or `%a`, It will be taken out as a normalizing replacemeent rule and deleted from the mapping. And rest is fixed according to the normalizing rule \"%a\": \"a%\".\n",
    "```\n",
    "\"f*a%\": \"ෆ්‍රේ\"\n",
    "\"f.a%\": \"ග්‍රේ\"\n",
    "\"fla%\": \"ක්‍රේ\"\n",
    "\"fma%\": \"ප්‍රේ\"\n",
    "```\n",
    "Now unique deduped mappings shoul be  523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variations of ් and ු are normalized since unicode should correctly render them through open-type rules.\n",
    "```\n",
    "\"A\": \"a\"\n",
    "\"=\": \"q\"\n",
    "\"+\": \"Q\"\n",
    "```\n",
    "\n",
    "leaving the following rules as is for clarity, even though they won't be used:\n",
    "```\n",
    "\"A\": \"්\"\n",
    "\"=\": \"ු\"\n",
    "\"+\": \"ූ\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizing_rules = {\"%a\": \"a%\", \"A\": \"a\", \"=\": \"q\", \"+\": \"Q\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mappings like 'C' and 'J' are bit confusing since they map to a combination of the format `<char><ZWJ>`. But zero width joiner is invicible and it might look like there is only one glyph there.\n",
    "```\n",
    "\"F\": \"ත්‍\"\n",
    "\"J\": \"න්‍\"\n",
    "\"C\": \"ක්‍\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few sanyaka represenations used in some places but missing in UCSC mapping is added. This confirms to the form of using \"`\" for sanyaka lakuna.\n",
    "```\n",
    "\"`o\": \"ඳ\"\n",
    "\"`P\": \"ඦ\"\n",
    "\"`v\": \"ඬ\"\n",
    "```\n",
    "Dwakara (`ද්‍<ZWJ><another char>`) is also missing from UCSC mapping. Those can be viewed as sanyaka forms of \"ධ\" and \"ව\". So \"`\" based sanyaka mapping is also added there.\n",
    "\n",
    "```\n",
    "\"Š\": \"ද්‍ධ\"\n",
    "\"`O\": \"ද්‍ධ\"\n",
    "\"„\": \"ද්‍ව\"\n",
    "\"`j\": \"ද්‍ව\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repaya + yansaya (œ) mapping has an issue. Since repaya needs come before the consonent and yansaya afterwards, simple replacement is not possible. \".œ\" is getting mapped to \"ග ර්‍්‍ය\", where the correct mapping would be \"ර්‍ග්‍ය\". This needs to be fixed by generation of mappings. For now fixing the special case mapping `\"hH_\": \"ර්ය\"` with `\"hH_\": \"ර්‍ය්‍ය\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
